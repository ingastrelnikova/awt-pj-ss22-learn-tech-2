{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "663531e1",
   "metadata": {},
   "source": [
    "# Competencies Extraction Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e84da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install spacy\n",
    "# python -m spacy download de_core_news_lg\n",
    "# pip install spacy-universal-sentence-encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d400ed",
   "metadata": {},
   "source": [
    "##  Tools and Libaries\n",
    "pandas: a software library written for the Python programming language for data manipulation and analysis\n",
    "\n",
    "spacy: an open-source software library for advanced natural language processing\n",
    "\n",
    "de_core_news_lg:  trained pipelines for German language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34f704ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "sp = spacy.load('de_core_news_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc67371",
   "metadata": {},
   "source": [
    "## Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f0a8e6d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  musikpersonal verwalten\n",
       "1                      strafvollzugsverfahr beaufsichtigen\n",
       "2                           unterdrückend praktik anwenden\n",
       "3        einhaltung vorschrift eisenbahnfahrzeuge überp...\n",
       "4                               verfügbar dienst ermitteln\n",
       "                               ...                        \n",
       "13886    beruflich leistungsfähigkeit nutzer nutzerinn ...\n",
       "13887                  beleuchtung transportgerät einbauen\n",
       "13888                       verarbeitung natürlich sprache\n",
       "13889                               bauarbeit koordinieren\n",
       "13890               absturzsicherung bordbretter anbringen\n",
       "Name: processedLabel, Length: 13891, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_processed = pd.read_csv(\"../data/labels_processed.csv\")['processedLabel']\n",
    "labels_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4dfa3961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        musikpersonal verwalten zuweise verwalten aufg...\n",
       "1        strafvollzugsverfahr beaufsichtigen überwachen...\n",
       "2        unterdrückend praktik anwenden ermittel repres...\n",
       "3        einhaltung vorschrift eisenbahnfahrzeuge überp...\n",
       "4        verfügbar dienst ermitteln ermitteln verschied...\n",
       "                               ...                        \n",
       "13886    beruflich leistungsfähigkeit nutzer nutzerinn ...\n",
       "13887    beleuchtung transportgerät einbauen einbau bel...\n",
       "13888    verarbeitung natürlich sprache technologie ikt...\n",
       "13889    bauarbeit koordinieren koordinierung tätigkeit...\n",
       "13890    absturzsicherung bordbretter anbringen anbring...\n",
       "Name: skill_info_processed, Length: 13891, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skills_info_processed = pd.read_csv(\"../data/skills_info_processed.csv\")['skill_info_processed']\n",
    "skills_info_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c2bde99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        schwierig klient patient angehörige kollege cl...\n",
       "1        aktuelles arbeitsrecht kurzbeschreibung  arbei...\n",
       "2        ambulant pflege rechtssicher handeln haftungsr...\n",
       "3        aufgabe gesetzlich betreuer reform betreuungsr...\n",
       "4        basisqualifikation ungelernt pflegekräft zerti...\n",
       "                               ...                        \n",
       "16847    monat weiterbildung organisation & führung lea...\n",
       "16848    conversion usability experte ziel maßnahme tei...\n",
       "16849    digital transformation management ziel maßnahm...\n",
       "16850    ecommerce geschäftsmodell ziel maßnahme teilne...\n",
       "16851    experte digital content creation teilnehmer di...\n",
       "Name: course_info_processed, Length: 16852, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "courses_info_processed = pd.read_csv(\"../data/courses_info_processed.csv\")['course_info_processed']\n",
    "courses_info_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8ef5be",
   "metadata": {},
   "source": [
    "## NLP Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c245d0a",
   "metadata": {},
   "source": [
    "### 1. Modified Ontology-based Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf67a49",
   "metadata": {},
   "source": [
    "`termStore:  {controlled vocabulary (vocabularies in label): URI}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "91eafb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "termStore = {}\n",
    "URI = 0\n",
    "for label_processed in labels_processed:\n",
    "    label_processed = sp(label_processed)\n",
    "    for word in label_processed:\n",
    "        word = word.text\n",
    "        if word not in termStore:\n",
    "            termStore[word] = URI\n",
    "            URI += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "256c69e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>controlledVocabulary</th>\n",
       "      <th>URI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>musikpersonal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>verwalten</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>strafvollzugsverfahr</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beaufsichtigen</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unterdrückend</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12122</th>\n",
       "      <td>scala</td>\n",
       "      <td>12122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12123</th>\n",
       "      <td>bodentragfähigkeit</td>\n",
       "      <td>12123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12124</th>\n",
       "      <td>bibliotheksartikel</td>\n",
       "      <td>12124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12125</th>\n",
       "      <td>absturzsicherung</td>\n",
       "      <td>12125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12126</th>\n",
       "      <td>bordbretter</td>\n",
       "      <td>12126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       controlledVocabulary    URI\n",
       "0             musikpersonal      0\n",
       "1                 verwalten      1\n",
       "2      strafvollzugsverfahr      2\n",
       "3            beaufsichtigen      3\n",
       "4             unterdrückend      4\n",
       "...                     ...    ...\n",
       "12122                 scala  12122\n",
       "12123    bodentragfähigkeit  12123\n",
       "12124    bibliotheksartikel  12124\n",
       "12125      absturzsicherung  12125\n",
       "12126           bordbretter  12126\n",
       "\n",
       "[12127 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(termStore.items(), columns = ['controlledVocabulary', 'URI'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea015bf",
   "metadata": {},
   "source": [
    "`sequenceStore: {URIs : (index, sequence consisted of controlled vocabularies (label))}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1286455b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequenceStore = {}\n",
    "for i, label_processed in enumerate(labels_processed):\n",
    "    URIs = []\n",
    "    label_processed = sp(label_processed)\n",
    "    for word in label_processed:\n",
    "        URIs.append(termStore[word.text])\n",
    "    sequenceStore[tuple(URIs)] = (i,label_processed.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "636ef1b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URIs</th>\n",
       "      <th>(index, label)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 1)</td>\n",
       "      <td>(0, musikpersonal verwalten)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(2, 3)</td>\n",
       "      <td>(1, strafvollzugsverfahr beaufsichtigen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(4, 5, 6)</td>\n",
       "      <td>(2, unterdrückend praktik anwenden)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(7, 8, 9, 10)</td>\n",
       "      <td>(3, einhaltung vorschrift eisenbahnfahrzeuge ü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(11, 12, 13)</td>\n",
       "      <td>(4, verfügbar dienst ermitteln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13877</th>\n",
       "      <td>(1802, 6820, 501, 502, 705, 1335)</td>\n",
       "      <td>(13886, beruflich leistungsfähigkeit nutzer nu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13878</th>\n",
       "      <td>(2206, 1899, 289)</td>\n",
       "      <td>(13887, beleuchtung transportgerät einbauen)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13879</th>\n",
       "      <td>(1743, 1332, 2355)</td>\n",
       "      <td>(13888, verarbeitung natürlich sprache)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13880</th>\n",
       "      <td>(3594, 478)</td>\n",
       "      <td>(13889, bauarbeit koordinieren)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13881</th>\n",
       "      <td>(12125, 12126, 1145)</td>\n",
       "      <td>(13890, absturzsicherung bordbretter anbringen)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13882 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    URIs  \\\n",
       "0                                 (0, 1)   \n",
       "1                                 (2, 3)   \n",
       "2                              (4, 5, 6)   \n",
       "3                          (7, 8, 9, 10)   \n",
       "4                           (11, 12, 13)   \n",
       "...                                  ...   \n",
       "13877  (1802, 6820, 501, 502, 705, 1335)   \n",
       "13878                  (2206, 1899, 289)   \n",
       "13879                 (1743, 1332, 2355)   \n",
       "13880                        (3594, 478)   \n",
       "13881               (12125, 12126, 1145)   \n",
       "\n",
       "                                          (index, label)  \n",
       "0                           (0, musikpersonal verwalten)  \n",
       "1               (1, strafvollzugsverfahr beaufsichtigen)  \n",
       "2                    (2, unterdrückend praktik anwenden)  \n",
       "3      (3, einhaltung vorschrift eisenbahnfahrzeuge ü...  \n",
       "4                        (4, verfügbar dienst ermitteln)  \n",
       "...                                                  ...  \n",
       "13877  (13886, beruflich leistungsfähigkeit nutzer nu...  \n",
       "13878       (13887, beleuchtung transportgerät einbauen)  \n",
       "13879            (13888, verarbeitung natürlich sprache)  \n",
       "13880                    (13889, bauarbeit koordinieren)  \n",
       "13881    (13890, absturzsicherung bordbretter anbringen)  \n",
       "\n",
       "[13882 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sequenceStore.items(), columns = ['URIs', '(index, label)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a81d555",
   "metadata": {},
   "source": [
    "The algorithm scans the tokenized courses information from the beginning until a word contained in the `termStore` is reached. Starting from this word a lookahead is performed searching for the longest sequence of words, which are contained in the `termStore`. As soon as a subsequent term is not included in the `termStore`, the `check_candidates` method to find all sequence still contained in the `sequenceStore` by using URIs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a277871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relations_ER(index_start, index_end):\n",
    "    URIs_candidates = []\n",
    "    word_candidates = []\n",
    "    relations = []\n",
    "    courses_info_processed_subset = courses_info_processed[index_start:index_end]\n",
    "    for i, course_info_processed in enumerate(courses_info_processed_subset):\n",
    "        index_course = index_start + i\n",
    "        for word in sp(course_info_processed):\n",
    "            word = word.text\n",
    "            if word != '--' and word in termStore:\n",
    "                word_candidates.append(word)\n",
    "                URIs_candidates.append(termStore[word])\n",
    "            else:\n",
    "                if URIs_candidates != []:\n",
    "                    URIs_candidates, relations = check_candidates(URIs_candidates, index_course, relations)\n",
    "                word_candidates = []\n",
    "            \n",
    "#             # approximate matching, results not good \n",
    "#             for key in termStore.keys():\n",
    "#                 if str(word) == key or key.startswith(str(word)):\n",
    "#                     word_candidates.append(key)\n",
    "#                     URIs_candidates.append(termStore[key])\n",
    "#                 else:\n",
    "#                     if URIs_candidates != []:\n",
    "#                         URIs_candidates, relations = check_candidates(URIs_candidates, index_course, relations)\n",
    "#                     word_candidates = []\n",
    "                    \n",
    "    URIs_candidates, relations = check_candidates(URIs_candidates, index_course, relations)\n",
    "    \n",
    "#     for relation in relations:\n",
    "#         print(courses['course_name'][relation[0]])\n",
    "#         print(' ---> ' + skills['preferredLabel'][relation[1]] + '   ' + skills['conceptUri'][relation[1]])\n",
    "#         print()\n",
    "    return relations\n",
    "\n",
    "        \n",
    "def check_candidates(URIs_candidates, index_course, relations):\n",
    "    n = len(URIs_candidates)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n+1):\n",
    "            URIs = tuple(URIs_candidates[i:j])\n",
    "            if URIs in sequenceStore:\n",
    "                index_label = sequenceStore[URIs][0]\n",
    "                if (index_course, index_label) not in relations:\n",
    "                    relations.append((index_course, index_label))\n",
    "    URIs_candidates = []\n",
    "    return URIs_candidates, relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cfc13",
   "metadata": {},
   "source": [
    "### 2. Universal Sentence Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d141923d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-02 10:23:24.606852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:961] could not open file to read NUMA node: /sys/bus/pci/devices/0000:26:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2022-07-02 10:23:24.607032: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607079: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607163: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607269: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607301: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607334: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-07-02 10:23:24.607339: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-07-02 10:23:24.608081: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import tensorflow_text\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual-large/3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5def728",
   "metadata": {},
   "source": [
    "#### Calculate skill embedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a3090b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_info_processed_embedings = []\n",
    "batch_size = 1000\n",
    "for i in range(0, len(skills_info_processed), batch_size):\n",
    "    skill_info_processed_embedings.extend(embed(skills_info_processed[i: i + batch_size]))\n",
    "skill_info_processed_embedings = np.array(skill_info_processed_embedings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a722a6c",
   "metadata": {},
   "source": [
    "#### Find course with related skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1e713838",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.45\n",
    "top_n = 15\n",
    "\n",
    "def get_relations_NN(index_start, index_end):\n",
    "    relations = []\n",
    "    courses_info_processed_subset = courses_info_processed[index_start:index_end]\n",
    "    for i, course_info_processed in enumerate(courses_info_processed_subset):\n",
    "        course_i = index_start + i\n",
    "        course_info_processed_embeding = embed(course_info_processed)\n",
    "        similarities = np.inner(course_info_processed_embeding, skill_info_processed_embedings)[0]\n",
    "        top_i = np.where(similarities >= threshold)[0]\n",
    "        top_similarities = similarities[similarities >= threshold]\n",
    "        related_skills_i_similarity = list(zip(top_i, top_similarities))\n",
    "        top_related_skills_i_similarity = sorted(related_skills_i_similarity, key = lambda x: x[1], reverse=True)[:top_n]\n",
    "        top_related_skills_i = list(map(lambda x: x[0], top_related_skills_i_similarity))\n",
    "        relations.extend(list(zip([course_i]*len(top_related_skills_i), top_related_skills_i)))\n",
    "    return relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e4d9a4",
   "metadata": {},
   "source": [
    "### Calculate id relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "899bdb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'NN'\n",
    "start, end = 0, len(courses_info_processed)\n",
    "\n",
    "if model == 'ER':\n",
    "    # Modified Ontology-based Entity Recognition\n",
    "    relations = get_relations_ER(start, end)\n",
    "    file_name = 'all_relations_ER.csv'\n",
    "    \n",
    "elif model == 'NN':\n",
    "    # Universal Sentence Encoder\n",
    "    relations = get_relations_NN(start, end)\n",
    "    file_name = 'all_relations_NN.csv'\n",
    "    \n",
    "else: raise Exception(\"Please set model to ER or NN\")\n",
    "\n",
    "course_ids = pd.read_csv(\"../data/all_courses.csv\")['course_id']\n",
    "skill_uris = pd.read_csv(\"../data/all_skills.csv\")['concept_uri']\n",
    "graph = []\n",
    "for relation in relations:\n",
    "    graph.append((course_ids[relation[0]],skill_uris[relation[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33afd64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graphp_df = pd.DataFrame(graph)\n",
    "graphp_df.columns =['course_id', 'concept_uri']\n",
    "graphp_df.to_csv(\"../data/{}\".format(file_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11bcaa6",
   "metadata": {},
   "source": [
    "### Map id relations to name relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6703729b",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = pd.read_csv('../data/all_courses.csv')[['course_id','course_name']]\n",
    "skills = pd.read_csv('../data/all_skills.csv')[['concept_uri','preferred_label']]\n",
    "id_relations = pd.read_csv(\"../data/{}\".format(file_name)).iloc[:,1:3]\n",
    "skill_dict = skills.set_index('concept_uri').to_dict()['preferred_label']\n",
    "course_dict = courses.set_index('course_id').to_dict()['course_name']\n",
    "name_relations = pd.DataFrame(columns=['course_name','skill_label'])\n",
    "name_relations['course_name'] = id_relations['course_id'].map(course_dict)\n",
    "name_relations['skill_label'] = id_relations['concept_uri'].map(skill_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8a286ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_name</th>\n",
       "      <th>skill_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"Schwierige\" Klienten? - Mit Patienten, Angehö...</td>\n",
       "      <td>in der Fachkrankenpflege kommunizieren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Schwierige\" Klienten? - Mit Patienten, Angehö...</td>\n",
       "      <td>Fachkrankenpflege</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Schwierige\" Klienten? - Mit Patienten, Angehö...</td>\n",
       "      <td>Feedback zum Kommunikationsstil von Patienten/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Schwierige\" Klienten? - Mit Patienten, Angehö...</td>\n",
       "      <td>bei Kommunikationsstörungen beraten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Schwierige\" Klienten? - Mit Patienten, Angehö...</td>\n",
       "      <td>Patienten/Patientinnen zu familiären Themen be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42587</th>\n",
       "      <td>Staatlich geprüfte/r Betriebswirt/in, Studiens...</td>\n",
       "      <td>elektronische Logistik für Soundanlagen managen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42588</th>\n",
       "      <td>Staatlich geprüfte/r Betriebswirt/in, Studiens...</td>\n",
       "      <td>Vorkehrungen für logistische Anforderungen an ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42589</th>\n",
       "      <td>Digital Transformation Management</td>\n",
       "      <td>ein Team leiten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42590</th>\n",
       "      <td>Digital Transformation Management</td>\n",
       "      <td>innovative Mobilitätslösungen entwickeln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42591</th>\n",
       "      <td>Experte im Digital Content Creation</td>\n",
       "      <td>digitales Lehrmaterial entwickeln</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42592 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             course_name  \\\n",
       "0      \"Schwierige\" Klienten? - Mit Patienten, Angehö...   \n",
       "1      \"Schwierige\" Klienten? - Mit Patienten, Angehö...   \n",
       "2      \"Schwierige\" Klienten? - Mit Patienten, Angehö...   \n",
       "3      \"Schwierige\" Klienten? - Mit Patienten, Angehö...   \n",
       "4      \"Schwierige\" Klienten? - Mit Patienten, Angehö...   \n",
       "...                                                  ...   \n",
       "42587  Staatlich geprüfte/r Betriebswirt/in, Studiens...   \n",
       "42588  Staatlich geprüfte/r Betriebswirt/in, Studiens...   \n",
       "42589                  Digital Transformation Management   \n",
       "42590                  Digital Transformation Management   \n",
       "42591                Experte im Digital Content Creation   \n",
       "\n",
       "                                             skill_label  \n",
       "0                 in der Fachkrankenpflege kommunizieren  \n",
       "1                                      Fachkrankenpflege  \n",
       "2      Feedback zum Kommunikationsstil von Patienten/...  \n",
       "3                    bei Kommunikationsstörungen beraten  \n",
       "4      Patienten/Patientinnen zu familiären Themen be...  \n",
       "...                                                  ...  \n",
       "42587    elektronische Logistik für Soundanlagen managen  \n",
       "42588  Vorkehrungen für logistische Anforderungen an ...  \n",
       "42589                                    ein Team leiten  \n",
       "42590           innovative Mobilitätslösungen entwickeln  \n",
       "42591                  digitales Lehrmaterial entwickeln  \n",
       "\n",
       "[42592 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_relations.to_csv('../data/name_relations_.csv')\n",
    "name_relations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b448aa",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "04446571",
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in [0.4, 0.42, 0.44, 0.46]:\n",
    "    for top_n in [5, 10, 15, 20]:\n",
    "        \n",
    "        start, end = 0, len(courses_info_processed)\n",
    "\n",
    "        # Universal Sentence Encoder\n",
    "        relations = get_relations_NN(start, end)\n",
    "        file_name = 'all_relations_NN_{}_{}.csv'.format(threshold, top_n)\n",
    "\n",
    "\n",
    "        course_ids = pd.read_csv(\"../data/all_courses.csv\")['course_id']\n",
    "        skill_uris = pd.read_csv(\"../data/all_skills.csv\")['concept_uri']\n",
    "        graph = []\n",
    "        for relation in relations:\n",
    "            graph.append((course_ids[relation[0]],skill_uris[relation[1]]))\n",
    "\n",
    "        graphp_df = pd.DataFrame(graph)\n",
    "        graphp_df.columns =['course_id', 'concept_uri']\n",
    "        graphp_df.to_csv(\"../data/{}\".format(file_name))\n",
    "\n",
    "        courses = pd.read_csv('../data/all_courses.csv')[['course_id','course_name']]\n",
    "        skills = pd.read_csv('../data/all_skills.csv')[['concept_uri','preferred_label']]\n",
    "        id_relations = pd.read_csv(\"../data/{}\".format(file_name)).iloc[:,1:3]\n",
    "        skill_dict = skills.set_index('concept_uri').to_dict()['preferred_label']\n",
    "        course_dict = courses.set_index('course_id').to_dict()['course_name']\n",
    "        name_relations = pd.DataFrame(columns=['course_name','skill_label'])\n",
    "        name_relations['course_name'] = id_relations['course_id'].map(course_dict)\n",
    "        name_relations['skill_label'] = id_relations['concept_uri'].map(skill_dict)\n",
    "        name_relations.to_csv('../data/name_relations_{}_{}.csv'.format(threshold, top_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75884809",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "63161bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "courses = pd.read_csv(\"../data/all_courses.csv\")\n",
    "labels = pd.read_csv(\"../data/all_skills.csv\")['preferred_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fd73f08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_processed = []\n",
    "for label in (labels):\n",
    "    label = sp(label)\n",
    "    label_processed = ''\n",
    "    for word in label:\n",
    "        word = word.lemma_.lower()\n",
    "        word = str(word)\n",
    "        if word != '--' and word != '' and word != ' ' and word != '\\xa0':\n",
    "            label_processed += word + ' '\n",
    "    labels_processed.append(label_processed[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "880a3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_processed_embeddings = embed(labels_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "98b2d2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = {}\n",
    "course_descriptions = courses['course_description']\n",
    "for course_description in course_descriptions:\n",
    "    course_description = sp(course_description)\n",
    "    for word in course_description:\n",
    "        if not word.is_stop and word.is_alpha:\n",
    "            word = word.lemma_.lower()\n",
    "            if word not in frequencies: frequencies[word] = 1\n",
    "            else: frequencies[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "2946284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = dict(sorted(frequencies.items(), key=lambda x: x[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71968f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold = 0.8\n",
    "# top_n = 5\n",
    "# sentences = sp(course_description).sents\n",
    "# for sentence in sentences:\n",
    "#     sentence_processed = []\n",
    "#     for word in sentence:\n",
    "#         if \"/-\" in str(word): word = sp(str(word).split(\"/-\")[0])[0]\n",
    "        \n",
    "#         if not word.is_stop and word.is_alpha:\n",
    "#             word = word.lemma_.lower()\n",
    "#             sentence_processed.append(word)\n",
    "#     if len(sentence_processed) != 0: \n",
    "#         sentence_processed_embedding = embed(sentence_processed)\n",
    "#         similarities = np.inner(sentence_processed_embedding, label_processed_embeddings)[0]\n",
    "#         top_i = np.where(similarities >= threshold)[0]\n",
    "#         top_similarities = similarities[similarities >= threshold]\n",
    "#         related_skills_i_similarity = list(zip(top_i, top_similarities))\n",
    "#         top_related_skills_i_similarity = sorted(related_skills_i_similarity, key = lambda x: x[1], reverse=True)[:top_n]\n",
    "#         top_related_skills_i = list(map(lambda x: x[0], top_related_skills_i_similarity))\n",
    "#         top_related_skills = list(map(lambda x: skill_labels[x], top_related_skills_i))\n",
    "#         print(top_related_skills)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efea6bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
